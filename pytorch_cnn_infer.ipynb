{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported - ready to use PyTorch 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Other libraries we'll use\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images are in the data/shapes folder\n",
    "data_path = 'shapes_data/'\n",
    "\n",
    "# # Get the class names\n",
    "# classes = os.listdir(data_path)\n",
    "# classes.sort()\n",
    "# print(len(classes), 'classes:')\n",
    "# print(classes)\n",
    "\n",
    "# # Show the first image in each folder\n",
    "# fig = plt.figure(figsize=(8, 12))\n",
    "# i = 0\n",
    "# for sub_dir in os.listdir(data_path):\n",
    "#     i+=1\n",
    "#     img_file = os.listdir(os.path.join(data_path,sub_dir))[0]\n",
    "#     img_path = os.path.join(data_path, sub_dir, img_file)\n",
    "#     img = mpimg.imread(img_path)\n",
    "#     a=fig.add_subplot(1, len(classes),i)\n",
    "#     a.axis('off')\n",
    "#     imgplot = plt.imshow(img)\n",
    "#     a.set_title(img_file)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Function to ingest data using training and test loaders\n",
    "# def load_dataset(data_path):\n",
    "#     # Load all of the images\n",
    "#     transformation = transforms.Compose([\n",
    "#         # transform to tensors\n",
    "#         transforms.ToTensor(),\n",
    "#         # Normalize the pixel values (in R, G, and B channels)\n",
    "#         transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "#     ])\n",
    "\n",
    "#     # Load all of the images, transforming them\n",
    "#     full_dataset = torchvision.datasets.ImageFolder(\n",
    "#         root=data_path,\n",
    "#         transform=transformation\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     # Split into training (70% and testing (30%) datasets)\n",
    "#     train_size = int(0.7 * len(full_dataset))\n",
    "#     test_size = len(full_dataset) - train_size\n",
    "#     train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "#     # define a loader for the training data we can iterate through in 50-image batches\n",
    "#     train_loader = torch.utils.data.DataLoader(\n",
    "#         train_dataset,\n",
    "#         batch_size=50,\n",
    "#         num_workers=0,\n",
    "#         shuffle=False\n",
    "#     )\n",
    "    \n",
    "#     # define a loader for the testing data we can iterate through in 50-image batches\n",
    "#     test_loader = torch.utils.data.DataLoader(\n",
    "#         test_dataset,\n",
    "#         batch_size=50,\n",
    "#         num_workers=0,\n",
    "#         shuffle=False\n",
    "#     )\n",
    "        \n",
    "#     return train_loader, test_loader\n",
    "\n",
    "\n",
    "# # Get the iterative dataloaders for test and training data\n",
    "# train_loader, test_loader = load_dataset(data_path)\n",
    "# print('Data loaders ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model class defined!\n"
     ]
    }
   ],
   "source": [
    "class PyTorchCNN(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(PyTorchCNN, self).__init__()\n",
    "        \n",
    "        # Our images are RGB, so input channels = 3. We'll apply 12 filters in the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # We'll apply max pooling with a kernel size of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # A second convolutional layer takes 12 input channels, and generates 12 outputs\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A third convolutional layer takes 12 inputs and generates 24 outputs\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
    "        # So our feature tensors are now 32 x 32, and we've generated 24 of them\n",
    "        # We need to flatten these and feed them to a fully-connected layer\n",
    "        # to map them to  the probability for each class\n",
    "        self.fc = nn.Linear(in_features=32 * 32 * 24, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use a relu activation function after layer 1 (convolution 1 and pool)\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "      \n",
    "        # Use a relu activation function after layer 2 (convolution 2 and pool)\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        \n",
    "        # Select some features to drop after the 3rd convolution to prevent overfitting\n",
    "        x = F.relu(self.drop(self.conv3(x)))\n",
    "        \n",
    "        # Only drop the features if this is a training pass\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 32 * 32 * 24)\n",
    "        # Feed to fully-connected layer to predict class\n",
    "        x = self.fc(x)\n",
    "        # Return log_softmax tensor \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "print(\"CNN model class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the trained model\n",
    "\n",
    "Now that we've trained and evaluated our model, we can use it to predict classes for new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circle\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = 'shapes_data/'\n",
    "model_file = 'shape_cnn/shape_classifier.pt'\n",
    "\n",
    "# Get the class names\n",
    "classes = os.listdir(data_path)\n",
    "classes.sort()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from random import randint\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image):\n",
    "    import numpy\n",
    "    \n",
    "    # Set the classifer model to evaluation mode\n",
    "    classifier.eval()\n",
    "    \n",
    "    # Apply the same transformations as we did for the training images\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    image_tensor = transformation(image).float()\n",
    "\n",
    "    # Add an extra batch dimension since pytorch treats all inputs as batches\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "\n",
    "    # Turn the input into a Variable\n",
    "    input_features = Variable(image_tensor)\n",
    "\n",
    "    # Predict the class of the image\n",
    "    output = classifier(input_features)\n",
    "    index = output.data.numpy().argmax()\n",
    "    return index\n",
    "\n",
    "\n",
    "# Function to create a random image (of a square, circle, or triangle)\n",
    "def create_image (size, shape):\n",
    "    from random import randint\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = (randint(0,200), randint(0,200), randint(0,200))\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'triangle':\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    else: # square\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "# Create a random test image\n",
    "classnames = os.listdir(data_path)\n",
    "classnames.sort()\n",
    "shape = classnames[randint(0, len(classnames)-1)]\n",
    "img = create_image ((128,128), shape)\n",
    "\n",
    "# Display the image\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "\n",
    "# Create a new model class and load the saved weights\n",
    "model = PyTorchCNN()\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "# Call the predction function\n",
    "index = predict_image(model, img)\n",
    "print(classes[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
